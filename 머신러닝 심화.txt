 임베딩  -> 딥러닝 자연어 처리의 기본 -> 문제점 : 단어는 문맥에 따라서 뜻이 달라질 수 있기 때문 ->  왜? -> 학습이 되어있지 않음.
 ㄴ 단어를 밀집 벡터의 형태로 표현하는 방법

 기존 LM의 문제점 : 언어 모델은 정방향 또는 역방향으로 진행이됨.
-> 하지만 언어의 문맥은 양방향을 통해서 결정이됨.

 언어 모델이 단방향이여만 할까? -> 양방향 언어모델을 만들 경우, 미리 예측할 단어에 대한 정보를 보게 되기 때문이다.
-> 문제 풀면서 답지를 보는 것과 비슷한 느낌.

 BERT -> 방대한 데이터로 사전 훈련된 MASKED언어 모델
	 -> BERT에 풀고자 하는 TASK(명령)에 맞는 추가적인 신경망을 추가
	 -> 풀고자 하는 Task의 오차에 맞추어 BERT를 학습.
		->이를 파인 튜닝(fine-tuning)이라 한다.
	-> BERT는 ELMo나 GPT-1과 마찬가지로 '문맥을 반영한 임베딩(Contextual Embedding)'

 ELMo -> 양방향이긴하지만 진정한 양방향은 아님.
 GPT -> 단방향
 BERT -> 양방향
	-> MLM이 성능의 대부분

 transformer
[SOS] : 문장의 시작을 알리는 token
[EOS] : 문장의 끝을 알리는 token

 Bert
[CLS] : Task-specific한 정보를 주기 위한 토큰
[SEP] : 문장 A,B를 구분하는 token
[MASK] : 예측하는 타겟

 BERT에서 사용하는 3가지 Embedding
 ㄴ Token Embedding은 우리가 알고있는 Input Word Embedding
 ㄴ Segment Embedding은 두 개의 문장을 구분하기 위한 Embedding
 ㄴ Position Embedding은 Transformer의 Positional Encoding(단어의 위치 정보를 포함시키고자 하는 것)을 대체할 수 있는 방법

 BERT에서는 Transformer의 위치 정보를 사인, 코사인 함수로 만드는 것이 아닌 "학습을 통해서 얻는 포지션 임베딩"

 Position Embedding
-> 위치 정보를 위한 임베딩층을 하나 더 사용.

 BERT에서 사용하는 임베딩 층
	ㄴ wordpiece embedding
	ㄴ position embedding
	ㄴ segment embedding

 전이 학습 -> 어떤 도메인의 데이터로 학습한 '모델을 다른 도메인의 데이터를 인식하는데 활용하여 성능 향상'을 꾀하는 기법
 ->> 왜 쓰느냐 ->> 데이터 부족으로인해 높은 성능을 달성하기 어려운 상황에 주로 사용.
	ㄴ 이런 대규모 데이터셋으로 훈련된 널리 쓰이는 모델을 재사용함으로써 더 적은 레이블 지정 데이터로 모델을 훈련시킬 수 있다.
	ㄴ 이를 통해 훈련 시간과 연산 리소스를 줄일 수 있다. 전이 학습을 사용하면 사전 훈련된 모델이 이전 학습을 기반으로 이미  가중치를 학습했기 때문에 신경망 가중치를 처음부터 학습하지 않음.

 전이학습 종류

-특징추출
    ㄴ 기존 모델의 마지막 레이어를 제거하고 새로운 레이어를 추가하여 새로운 문제에 맞게 학습함.
    ㄴ 기존 모델의 특징 추출 능력을 활용하여 새로운 문제에 대한 특징을 추출
    ㄴ 새로운 데이터가 충분하지 않은 경우에 유용 함.

-미세 조정(fine-tuning)
    ㄴ 기존 모델의 모든 레이어를 학습에 사용함.
    ㄴ 새로운 데이터에 맞게 모델의 가중치를 조정함.
    ㄴ 새로운 데이터가 충분한 경우에 유용 함.

 fine tuning
	ㄴ 정의 : 미리 학습된 모델을 새로운 작업에 맞게 미세하게 조정하는 기술
	ㄴ 방식 : 모델의 일부 또는 전체 레이어를 새로운 데이터셋으로 학습
	ㄴ 장점 : 높은 정확도
	ㄴ 단점 : 많은 데이터 필요, Labelling(Annotation) 작업 필요.
	ㄴ 활용 분야 : 특정 작업에 대한 모델 성능 향상
	ㄴ 예시 : 이미지 분류 모델을 특정 객체 분류에 맞게 학습

 Prompt Engineering
	ㄴ 정의 : 프롬프트를 사용하여, 미리 학습된 모델의 '출력을 제어하는 기술'
	ㄴ 방식 : 프롬프트를 변경하여 모델의 '출력'을 유도
	ㄴ 장점 : 빠르고 간편
	ㄴ 단점 : 모델의 내적 작동 방식 이해 필요, 정보의 신뢰성(Hallucination), 예제 데이터의 보안문제
	ㄴ 활용 분야 : 다양한 직업에 대한 모델 활용
	ㄴ 적합한 경우 : 데이터 확보에 대한 어려움
	ㄴ 예시 : 챗봇 모델에게 다양한 질문을 하도록 유도
//5장

 Hallucination : LLM은 학습 데이터에 존재하는 편향이나 오류를 반영하거나, 학습 과정에서 발생하는 오류로, '실제로는 사실이 아닌 정보를 생성하는 문제'가 발생
	ㄴ '사실적으로 오류가 있는 정보 생성'
	ㄴ '논리적으로 모순되는 정보 생성'
	ㄴ '존재하지 않는 정보 생성'
	ㄴ' 비속하거나 공격적인 정보 생성'
		-> Hallucination 해결 방안
			ㄴ 데이터 품질 관리
			ㄴ 다양한 데이터 활용
			ㄴ 학습 과정 개선
			ㄴ 평가 지표 개선
			ㄴ 사용자 교육

 LLM의 문제점 - 최신 정보를 업데이트 하려면 시간이 많이 필요
	        - Local 정보에 대해서는 학습이 되지않아 Hallucination을 많이 발생 시킴

 좋은 prompt 구성요건
	ㄴ context
	ㄴ Task
	ㄴ Persona
	ㄴ Exemplar
	ㄴ Format
	ㄴ Tone

 Full Fine Tunning -
	ㄴ 1. 도메인에 맞는 Dataset을 구축
	ㄴ 2.데이터의 전처리 수행
	ㄴ 3. 모델의 구조 및 환경 설정
	ㄴ 4. 모델의 학습
	ㄴ 5. 모델의 성능 평가
	ㄴ 6. 원하는 모델의 성능이 나올 때까지 3~5번 과정을 반복 학습
 ㄴ 단점 : 'Pre-trained LLM만큼의 시간과 많은 자원을 필요로하지는 않지만 상당한 자원과 시간을 필요로 한다.'

 PEFT -> Prefix Tunining
	 ㄴ 1. 개념 : PEFT는 사전 학습된 언어 모델의 입력에 학습 가능한 연속적인 벡터(prefix)를 추가하는 방식. prefix는 테스크에 특화된 정보를 담고 있으며, 모델의 나머지 부분은 고정된 상태로 유지.
	 ㄴ 2. 작동 방식 : 모델의 각 레이어 입력에 학습 가능한 prefix 벡터를 추가. 이 prefix는 테스크에 맞게 최적화되며, 모델의 출력을 조정하는 역할을 한다.
	 ㄴ 3. 장점 - 매개변수 효율성 : 전체 모델을 미세 조정하는 대신 소수의 매개변수만 학습하므로 메모리 사용량이 크게 줄어든다.
		   - 빠른 학습 : 학습해야 할 매개변수가 적어 학습 속도가 빠르다.
		   - 다중 테스크 적용 용이 : 하나의 모델에 여러 개의 prefix를 사용하여 다양한 테스크를 수행 할 수 있다.
		   - 원본 모델 보존 : 기존 모델의 매개변수를 변경하지 않아 원본 지식을 보존한다.
	 ㄴ 4. 적용 분야 -텍스트 생성, 요약, 기계 번역 등 다양한 NLP테스크에 적용 가능하다.
		         - 특히 큰 규모의 언어 모델에 효과적이다.
	 ㄴ 5. 일부 테스크에서 전체 모델 파인튜닝보다 성능이 약간 떨어질 수 있다. prefix의 최적 길이를 결정하는 것이 어려운 문제이다.

          -> P-tuning : 모델 자체의 파라메터를 직접 변경하는 대신 모델 '입력에 사용되는 프롬프트를 조정'하여 성능을 향상시킴.
	 ㄴ 1. 개념 : P-tunning은 '프롬프트 튜닝'의 연속적인 버전.
		이산적인 프롬프트 토큰 대신 연속적인 벡터를 사용.
	 ㄴ 2. 작동방식 : 입력 시퀀스의 시작 부분에 소수의 연속적인 임베딩 벡터(가상 토큰)를 추가.
		이 가상 토큰들은 학습 가능하며, 테스크에 맞게 최적화된다.
		모델의 나머지 부분은 고정된 상태로 유지하면 된다.
	 ㄴ 3. Prefix Tunning과의 차이점 : P-tunning은 주로 입력 레이어에만 적용되는 반면, Prefix Tunning은 모든 레이어에 적용됨.
		P-tunning은 일반적으로 더 적은 수의 파라미터를 사용.
	 ㄴ 4. 장점 - 매개변수 효율성 : 전체 모델을 미세 조정하는 것보다 훨씬 적은 매개변수만 학습.
		-메모리 효율성 : 저장해야 할 매개변수가 적어 메모리 사용량이 줄어든다.
		-빠른 학습 및 추론: 학습해야 할 매개변수가 적어 학습과 추론 속도가 빠름.
		-원본 모델 보존 : 기존 모델의 매개변수를 변경하지 않는다.
	 ㄴ 5. 적용 분야 : 문장 분류, 개체명 인식, 관계 추출 등 다양한 NLP 테스크에 적용 가능.
		특히 적은 양의 학습 데이터로도 좋은 성능을 보일 수 있다.
	 ㄴ 6. 한계 : 일부 복잡한 테스크에서는 전체 모델 파인튜닝보다 성능이 떨어질 수 있다.
		최적의 가상 토큰 수를 결정하는 것이 도전적일 수 있다.
 PEFT : Prompt tuning
	ㄴ 1. 개념 : Prompt tuning은 모델의 입력에 학습 가능한 연속적인 프롬프트 토큰을 추가한다.
		   이 프롬프트 토큰들은 특정 작업에 맞게 최적화 되며, 모델의 나머지 부분은 고정 된 상태이다.
	ㄴ 2.작동 방식 : 입력 시퀀스의 시작 부분에 소수의 학습가능한 토큰(10~100개가 보통)을 추가한다.
			이 토큰들은 연속적인 벡터공간에서 최적화 된다.
			모델은 이 프롬프트를 통해 특정 작업에 맞는 출력을 생성하도록 유도한다.
	ㄴ 3. 장점 : -매개변수 효율성 : 전체 모델을 미세 조정하는 것 보다, 훨씬 적은 매개변수만 학습.
		    - 메모리의 효율성 : 저장해야 할 매개변수가 적어 메모리 사용량이 크게 줄어든다.
		    - 유연성 : 하나의 모델로 여러 작업을 수행할 수 있다.(작업별로 다른 프롬프트를 사용)
		    - 원본 모델 보존 : 기본 모델의 매개변수를 변경하지 않아 원본지식을 보존한다.
	ㄴ 4. 다른 기법과 비교 :
		    -Fine-Tuning : 전체모델 파라매터를 조정하는 반면, prompt Tuning은 프롬프트만 조절
 		    - P-tuning : 입력 레이어에서만 적용되는 반면, prompt tuning은 입력에 직접 추가된다.
		    - Prefix tuning : 모든 레이어에 적용되는 반면, prompt tuning은 입력에만 적용된다.
	ㄴ5. 적용 분야 : 텍스트 분류, 질문 답변, 요약, 기계 번역 등 다양한 NLP작업에 적용 가능.
			특히 대규모 언어 모델에 효과적.
	ㄴ 6. 한계 : 모델 크기가 작을 경우 전통적인 파인튜닝보다 성능이 떨어질 수 있다.
			최적의 프롬프트 길이를 결정하는 것이 도전적인 문제일 수 있다.

 Prefix Tuning - 추가되는 항목 : 프리픽스 토큰
	      - 위치 : 입력 시퀀스의 앞부분
	      - 형식 : 토큰 형태
	      - 용도 : 텍스트 생성, 문서 요약
	      - 효율성 : 간단하고 효율적인 접근 방법

 P-Tuning - 추가되는 항목 : 연속적인 프롬프트 벡터
	 - 위치 : 입력 시퀀스의 여러 위치
	 - 형식 : 임베딩 벡터 형태
	 - 용도 : 텍스트 분류, 텍스트 생성
	 - 효율성 : 모델의 내적 구조를 더 깊이 활용

 Prompt Tuning - 추가되는 항목 : 텍스트 프롬프트
	        - 위치 : 입력 시퀀스의 앞부분
	        - 형식 : 텍스트 형식
	        - 용도 : 질문 응답, 문서 생성
	        - 효율성 : 특성 작업에 쉽게 맞출 수 있는 텍스트 기반 접근

 PEFT - LoRA : 기존 Fine Tuning 방식과 달리 LoRA는 모델의 모든 파라메터를 직접 변경하는 대신, 모델의 Low rank adapter를 통해 Fine Tuning을 수행.
 ㄴ LoRA의 작동 방식 
	1. Pre-trained LLM 모델 로드 : 먼저, 다양한 작업에 활용 가능하도록 사전 학습된 LLM 모델을 로드
	2. Low Rank adapter 생성 : 학습하고자 하는 특정 작업에 맞게 Low rank adapter를 생성한다. Low rank adapter는 모델의 입력과 출력 사이에 작동하는 작은 신경망 모듈 임.
	3. Fine Tuning : 학습 데이터를 사용하여 Low rank adapter만을 Fine Tuning한다. Fine Tuning과정에서 Low rank adapter는 학습 데이터의 패턴을 학습하고, 모델의 출력을 원하는 방향으로 조정한다.

 Slot 정의
 ㄴ 슬롯은 대화 시스템에서 특정한 정보를 수집하기 위해 사용되는 변수를 의미. 예를 들어, 레스토랑 예약 시스템에서는 "날짜", "시간", "사람 수"와 같은 슬롯이 있을 수 있다.
 ㄴ 사용자가 제공하는 정보에 따라 슬롯을 채우는 과정. 예를 들어, "내일 저녁 7시에 4명을 위한 예약을 하고 싶어요" 라는 문장을 통해 날짜, 시간, 사람 수 슬롯을 채울 수 있다.
 Unslot : 슬롯이 더 이상 필요하지 않거나 대화의 다른 단계로 넘어갈 때 슬롯을 비우거나 제거하는 과정이다.
 ㄴ 소프트웨어의 특정 기능(슬롯)을 제거하는 업데이트를 의미할 수 있다. 예를 들어, 불필요한 기능을 제거하여 소프트웨어를 간소화하거나 최적화하는 경우를 의미
 ㄴ Lama3 unslot 버전은 Alpaca prompt를 사용한다. 그래서 lama3 와 다르게 앞선 데이터의 변환이 필요함.

 Alpaca Prompt 형식 
 ㄴ 1. Instruction (지시사항) 모델이 수행해야 할 구체적인 작업을 설명하는 부분.
	 ㄴ 이 작업은 질문에 답변하거나 특정한 태스크를 완료하는 것이다.
 ㄴ 2. Input : 작업에 대한 추가적인 세부 사항이나 질문을 위한 입력.
	ㄴ 반드시 필요한 것은 아니지만, 문맥을 제공하여 모델이 더 정확한 답변을 생성할 수 있도록 한다.
 ㄴ 3.Output : 모델이 생성한 답변으로, Instruction과 Input에 따라 해당 질문에 대한 답을 제공한다.

 Streamlit 으로 개발한 chat-bot interface를 Google의 LLM인 Gemini-pro로 API 연결, Streamlit을 사용하면 복잡한 웹 개발 지식 없이도 데이터 시각화와 대화형 도구를 웹 애플리케이션으로 만들 수 있다.
 ㄴ Gemini : OpenAI의 GPT 시리즈의 대항마로 출시한 Google의 Gemini는 3가지 버전으로 출시되었으며, 현재는 Gemini Pro만 활용가능.

LangChain의 Langserve는 언어 모델 기반 애플리케이션을 쉽게 배포하고 관리할 수 있도록 도와주는 강력한 도구이고 이를 통해 개발자는 모델 배포 및 운영의 복잡성을 중리고, 효율적으로 애플리케이션을 개발하고 관리할 수 있다. Langserve는 확장성, 성능, 사용자 친화성, 보안 등 다양한 측면에서 최적화된 기능을 제공하여, NLP 애플리케이션 개발에 유용한 도구이다.
Langserve는 언어 모델을 RESTful API 형태로 쉽게 배포하고 관리할 수 있는 기능을 제공한다. 이를 통해 개발자는 복잡한 모델 배포 작업을 간소화하고, 모델의 운영 및 유지보수를 쉽게 할 수 있게 한다.

Ngrok은 로컬에서 실행 중인 웹 서버를 공용 URL로 노출시켜주는 도구이다. 개발자는 로컬에서 실행되는 애플리케이션을 외부 인터넷 사용자 또는 서비스와 쉽게 공유할 수 있다. Ngrok은 주로 웹 개발 및 디버깅, 테스트, 임시 웹 사이트 호스팅 등에 사용된다.
